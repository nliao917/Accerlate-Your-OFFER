{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# do the LDA\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import pprint\n",
    "import nltk\n",
    "from nltk import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BA=pd.read_csv('BA')\n",
    "df_DS=pd.read_csv('DS')\n",
    "df_DA=pd.read_csv('DA')\n",
    "df_DE=pd.read_csv('DE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words = STOPWORDS.union(set(['experience', 'work','requirements','ability','years','analyst',\n",
    "                                     'required','including','best','new','applicants','jobs','candidate',\n",
    "                                     'help','regard','qualified','employment','consideration','applications',\n",
    "                                     'position','able','application','role','business','analysis','analyze','data'\n",
    "                                    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_freq_filter(df):\n",
    "    l1=\"\"\n",
    "    for i in df_BA.index:\n",
    "        sents=df_BA.loc[i]['JD']\n",
    "        l1+=(sents.replace('\\n',''))\n",
    "    word_tokens = word_tokenize(l1)\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    wordlist=[word for word in word_tokens if word.isalnum() and word not in stop_words]\n",
    "    full_text=\"\"\n",
    "    for word in wordlist:\n",
    "        full_text+=word+\" \"\n",
    "    allWords = nltk.tokenize.word_tokenize(full_text)\n",
    "    allWordDist = nltk.FreqDist(w.lower() for w in allWords)\n",
    "    mostCommon= allWordDist.most_common(500)\n",
    "    common_words = []\n",
    "    for item in mostCommon:\n",
    "        common_words.append(item[0])\n",
    "    leastCommon= allWordDist.most_common()[:-100-1:-1]\n",
    "    least_words = []\n",
    "    for item in leastCommon:\n",
    "        least_words.append(item[0])\n",
    "    return common_words+least_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def lda(df,num_topics = 3,passes = 30,num_words=8):\n",
    "    l1=[]\n",
    "    for i in df.index:\n",
    "        sents=df.loc[i]['JD']\n",
    "        l1.append(sents.replace('\\n',''))\n",
    "    \n",
    "    texts = [[word for word in story.lower().split()\n",
    "            if word not in my_stop_words and word not in freq_words and word.isalnum()]\n",
    "            for story in l1]\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    \n",
    "    \n",
    "    lda = LdaModel(corpus,\n",
    "              id2word=dictionary,\n",
    "              num_topics=num_topics,\n",
    "              passes=passes)\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    pp.pprint(lda.print_topics(num_words))\n",
    "    \n",
    "    res=[]\n",
    "    \n",
    "    for i in range(3):\n",
    "        res.append(lda.show_topic(i))\n",
    "    res1=[]\n",
    "    for index in res:\n",
    "        for i,j in index:\n",
    "            res1.append(i)\n",
    "    \n",
    "    return res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.003*\"Ã¢\" + 0.002*\"day\" + 0.002*\"common\" + 0.002*\"party\" + '\n",
      "        '0.002*\"concise\" + 0.002*\"corporate\" + 0.002*\"3rd\" + 0.002*\"input\" + '\n",
      "        '0.002*\"challenges\" + 0.002*\"skillsstrong\"'),\n",
      "    (   1,\n",
      "        '0.002*\"texas\" + 0.002*\"quantitative\" + 0.002*\"human\" + '\n",
      "        '0.002*\"judgment\" + 0.002*\"employee\" + 0.002*\"quickly\" + '\n",
      "        '0.002*\"learning\" + 0.002*\"participates\" + 0.002*\"digital\" + '\n",
      "        '0.002*\"essential\"'),\n",
      "    (   2,\n",
      "        '0.002*\"handle\" + 0.002*\"line\" + 0.002*\"available\" + 0.002*\"applying\" '\n",
      "        '+ 0.002*\"release\" + 0.002*\"credit\" + 0.002*\"provider\" + 0.002*\"basis\" '\n",
      "        '+ 0.002*\"asset\" + 0.002*\"diverse\"')]\n"
     ]
    }
   ],
   "source": [
    "freq_words=word_freq_filter(df_BA)\n",
    "BA_lda=lda(df_BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.029*\"statistical\" + 0.017*\"interpret\" + 0.017*\"packages\" + '\n",
      "        '0.011*\"etl\" + 0.010*\"sources\" + 0.009*\"programming\" + '\n",
      "        '0.009*\"optimize\" + 0.009*\"collection\" + 0.009*\"amounts\" + '\n",
      "        '0.009*\"primary\"'),\n",
      "    (   1,\n",
      "        '0.007*\"statistical\" + 0.005*\"clinical\" + 0.003*\"public\" + '\n",
      "        '0.003*\"programming\" + 0.002*\"collection\" + 0.002*\"evaluation\" + '\n",
      "        '0.002*\"integrity\" + 0.002*\"school\" + 0.002*\"sources\" + 0.002*\"sas\"'),\n",
      "    (   2,\n",
      "        '0.006*\"statistical\" + 0.005*\"visualization\" + 0.005*\"quantitative\" + '\n",
      "        '0.003*\"sources\" + 0.003*\"analytic\" + 0.003*\"actionable\" + 0.003*\"bi\" '\n",
      "        '+ 0.003*\"sets\" + 0.003*\"power\" + 0.003*\"programming\"')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['statistical',\n",
       " 'interpret',\n",
       " 'packages',\n",
       " 'etl',\n",
       " 'sources',\n",
       " 'programming',\n",
       " 'optimize',\n",
       " 'collection',\n",
       " 'amounts',\n",
       " 'primary',\n",
       " 'statistical',\n",
       " 'clinical',\n",
       " 'public',\n",
       " 'programming',\n",
       " 'collection',\n",
       " 'evaluation',\n",
       " 'integrity',\n",
       " 'school',\n",
       " 'sources',\n",
       " 'sas',\n",
       " 'statistical',\n",
       " 'visualization',\n",
       " 'quantitative',\n",
       " 'sources',\n",
       " 'analytic',\n",
       " 'actionable',\n",
       " 'bi',\n",
       " 'sets',\n",
       " 'power',\n",
       " 'programming']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words=word_freq_filter(df_DA)\n",
    "DA_lda=lda(df_DA)\n",
    "DA_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.016*\"statistical\" + 0.009*\"machine\" + 0.008*\"learning\" + '\n",
      "        '0.008*\"analytic\" + 0.008*\"scientist\" + 0.006*\"clinical\" + '\n",
      "        '0.006*\"predictive\" + 0.005*\"techniques\" + 0.005*\"algorithms\" + '\n",
      "        '0.005*\"visualization\"'),\n",
      "    (   1,\n",
      "        '0.023*\"machine\" + 0.021*\"learning\" + 0.016*\"statistical\" + '\n",
      "        '0.009*\"quantitative\" + 0.007*\"techniques\" + 0.006*\"programming\" + '\n",
      "        '0.006*\"predictive\" + 0.006*\"python\" + 0.006*\"big\" + '\n",
      "        '0.005*\"algorithms\"'),\n",
      "    (   2,\n",
      "        '0.020*\"quantum\" + 0.009*\"ml\" + 0.007*\"machine\" + 0.006*\"algorithms\" + '\n",
      "        '0.006*\"qiskit\" + 0.005*\"computers\" + 0.005*\"learning\" + '\n",
      "        '0.005*\"looking\" + 0.005*\"linear\" + 0.005*\"diverse\"')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['statistical',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'analytic',\n",
       " 'scientist',\n",
       " 'clinical',\n",
       " 'predictive',\n",
       " 'techniques',\n",
       " 'algorithms',\n",
       " 'visualization',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'statistical',\n",
       " 'quantitative',\n",
       " 'techniques',\n",
       " 'programming',\n",
       " 'predictive',\n",
       " 'python',\n",
       " 'big',\n",
       " 'algorithms',\n",
       " 'quantum',\n",
       " 'ml',\n",
       " 'machine',\n",
       " 'algorithms',\n",
       " 'qiskit',\n",
       " 'computers',\n",
       " 'learning',\n",
       " 'looking',\n",
       " 'linear',\n",
       " 'diverse']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words=word_freq_filter(df_DS)\n",
    "DS_lda=lda(df_DS)\n",
    "DS_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.011*\"aws\" + 0.009*\"big\" + 0.007*\"engineer\" + 0.007*\"infrastructure\" '\n",
      "        '+ 0.006*\"pipelines\" + 0.006*\"etl\" + 0.006*\"relational\" + '\n",
      "        '0.005*\"python\" + 0.005*\"programming\" + 0.005*\"pipeline\"'),\n",
      "    (   1,\n",
      "        '0.009*\"etl\" + 0.008*\"python\" + 0.008*\"pipelines\" + 0.007*\"big\" + '\n",
      "        '0.007*\"azure\" + 0.006*\"engineer\" + 0.006*\"aws\" + 0.006*\"warehouse\" + '\n",
      "        '0.005*\"bi\" + 0.005*\"learning\"'),\n",
      "    (   2,\n",
      "        '0.016*\"big\" + 0.009*\"hadoop\" + 0.007*\"azure\" + 0.006*\"spark\" + '\n",
      "        '0.006*\"programming\" + 0.005*\"etl\" + 0.005*\"engineer\" + '\n",
      "        '0.005*\"pipelines\" + 0.004*\"python\" + 0.004*\"streaming\"')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['aws',\n",
       " 'big',\n",
       " 'engineer',\n",
       " 'infrastructure',\n",
       " 'pipelines',\n",
       " 'etl',\n",
       " 'relational',\n",
       " 'python',\n",
       " 'programming',\n",
       " 'pipeline',\n",
       " 'etl',\n",
       " 'python',\n",
       " 'pipelines',\n",
       " 'big',\n",
       " 'azure',\n",
       " 'engineer',\n",
       " 'aws',\n",
       " 'warehouse',\n",
       " 'bi',\n",
       " 'learning',\n",
       " 'big',\n",
       " 'hadoop',\n",
       " 'azure',\n",
       " 'spark',\n",
       " 'programming',\n",
       " 'etl',\n",
       " 'engineer',\n",
       " 'pipelines',\n",
       " 'python',\n",
       " 'streaming']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words=word_freq_filter(df_DE)\n",
    "DE_lda=lda(df_DE)\n",
    "DE_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LDA_List', 'w') as f:\n",
    "      \n",
    "    write = csv.writer(f)\n",
    "      \n",
    "    write.writerow(BA_lda)\n",
    "    write.writerow(DA_lda)\n",
    "    write.writerow(DS_lda)\n",
    "    write.writerow(DE_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match Topic to Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'get_document_topics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fcdec7f72ab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moperator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitemgetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_document_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_document_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'get_document_topics'"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "lda.get_document_topics(corpus_new[0],minimum_probability=0.05,per_word_topics=False)\n",
    "sorted(lda.get_document_topics(corpus_new[0],minimum_probability=0,per_word_topics=False),key=itemgetter(1),reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
